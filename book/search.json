[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TBEP-CC",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "The Tampa Bay Estuary Program compiles environmental data from multiple partners to report on the status and trends of key indicators of bay health (Monitoring and Indicators Plan). Indicators and reporting methods currently exist for several components of the CCMP, including water quality, benthic and sediment condition, fish communities, seagrasses, and tidal creeks. Open-source methods have been developed using the tbeptools R package (Beck, Schrandt, et al. 2021) that facilitates data synthesis and routine reporting for each of these indicators.\nAdditional indicators of bay health will complement the existing set of indicators. Key indicators currently missing from TBEP routine reporting products include those related to climate change.  The Tampa Bay Regional Planning Council has produced the Regional Resilience Action Plan (RRAP) to assist local governments and municipalities in planning resilience activities in response to climate change.  Fundamental to these activities is the identification of robust indicators of the local effects of climate change.  These may include data descriptive of sea-level rise, droughts, heat waves, or storm frequency/intensity.  The TBEP is supportive of these efforts and intends to identify several climate change indicators that can be operationalized for routine reporting, either through conventional summary graphics or more interactive web-based platforms.\n\nThis project will identify appropriate climate change indicators to support the TBEP and its partners in making informed planning decisions.  Although the primary goal of TBEP is the management of bay health, these indicators could also be used to support community resilience planning as described in the RRAP.  Appropriate data sources will be identified, with emphasis on those that are stable and planned to be reliable sources in the future.  Identifying indicators that represent relative risk of climate change impacts will be emphasized, as opposed to indicators that simply measure change.  All project activities will leverage open science principles as described in the TBEP Strategic Plan (Burke and Amaral 2020) and Data Management SOP (Beck, Raulerson, et al. 2021).\n\n\n\n\n\n\nBeck, Marcus W., G. E. Raulerson, M. C. Burke, J. Whalen, S. Scolaro, and E. T. Sherwood. 2021. “Tampa Bay Estuary Program: Data Management Standard Operating Procedures.” St. Petersburg, Florida.\n\n\nBeck, Marcus W., Meagan N. Schrandt, Michael R. Wessel, Edward T. Sherwood, Gary E. Raulerson, Adhokshaja Achar Budihal Prasad, and Benjamin D. Best. 2021. “Tbeptools: An R Package for Synthesizing Estuarine Data for Environmental Research.” Journal of Open Source Software 6 (65): 3485. https://doi.org/10.21105/joss.03485.\n\n\nBurke, M., and M. Amaral. 2020. “2021-2025 Strategic Plan.” St. Petersburg, Florida.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Task 1. Assessment of available data and coverage\nData descriptive of the risks of climate change can be obtained from several sources. These may include weather or climatological data, long-term tidal gauge data, or in situ water measurements responsive to climate change. Weather and climatological data could be obtained from local weather stations with long-term data, e.g., Tampa International Airport, and could include measures of air temperature, precipitation, and/or storm intensity/frequency. Tidal gauge data are readily available from the NOAA PORTS data retrieval system. Lastly, in situ water measurements could include water temperature, changes in flow hydrology, salinity, and/or pH. Data used to evaluate potential risks related to ocean acidification should also be explored.\nThe permanency and ease of access of each data source should be noted when making recommendations on indicators to operationalize. Further, indicators that communicate the risks associated with climate change are preferred, as opposed to those that simply indicate change. An example is the number of days in a year when temperature exceeds a critical threshold, as compared to temperature alone. An additional example is frequency of sunny day flooding events, as compared to tidal gauge measurements alone.\nCode\n# turn off all chunks by default\nknitr::opts_chunk$set(eval = FALSE)\nCode\n# options(repos=c(CRAN=\"https://cran.mirror.garr.it/CRAN/\"))\n# install.packages(c(\"sf\",\"terra\"), type = \"binary\")\n# renv::snapshot()\n# renv::clean()\n# renv::rebuild()\n# built from source: sp, survival, rnoaa, tbeptools\n\nif (!\"librarian\" %in% rownames(installed.packages()))\n  install.packages(\"librarian\")\nlibrarian::shelf(\n  dplyr, dygraphs, glue, here, htmltools, leaflet, leaflet.extras2, lubridate, \n  sf, stringr, tbep-tech/tbeptools, prism, purrr,\n  RColorBrewer, readr, rnoaa, terra, tidyr, webshot2,\n  quiet = T)\n\n# explicitly list packages for renv::dependencies(); renv::snapshot()\nlibrary(dplyr)\nlibrary(dygraphs)\nlibrary(glue)\nlibrary(here)\nlibrary(leaflet)\nlibrary(librarian)\nlibrary(lubridate)\nlibrary(RColorBrewer)\nlibrary(prism)\nlibrary(purrr)\nlibrary(readr)\nlibrary(rnoaa)\nlibrary(sf)\nlibrary(stringr)\nlibrary(tbeptools)\nlibrary(terra)\nlibrary(tidyr)\nlibrary(webshot2)\n\noptions(readr.show_col_types = F)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#air",
    "href": "data.html#air",
    "title": "2  Data",
    "section": "2.2 Air",
    "text": "2.2 Air\nnoaacrwsstDaily\n\n2.2.1 Observed\nThe rnoaa R package uses NOAA NCDC API v2, which only goes to 2022-09-15.\n\nNCEI Web Services | Climate Data Online (CDO) | National Center for Environmental Information (NCEI)\nData Tools | Climate Data Online (CDO) | National Climatic Data Center (NCDC)\n\n\n2.2.1.1 Weather stations\n\nTampa International Airport\n\nStart Date: 1939-02-01\nEnd Date: today - 3 days\n\n\nGot token at ncdc.noaa.gov/cdo-web/token. Added variable NOAA_NCDC_CDO_token to:\n\nlocally:\nfile.edit(\"~/.Renviron\")\non GitHub: Repository secrets in Actions secrets · tbep-tech/climate-change-indicators\nGCHN readme\n\nPRCP: Precipitation (tenths of mm)\nTMAX: Maximum temperature (tenths of degrees C)\nTMIN: Minimum temperature (tenths of degrees C)\n\n\n\n\nCode\n# provide NOAA key\noptions(noaakey = Sys.getenv(\"NOAA_NCDC_CDO_token\"))\n\n# Specify datasetid and station\nstn          &lt;- \"GHCND:USW00012842\" # TAMPA INTERNATIONAL AIRPORT, FL US\nstn_csv      &lt;- here(\"data/tpa_ghcnd.csv\")\nstn_meta_csv &lt;- here(\"data/tpa_meta.csv\")\n\nif (!file.exists(stn_meta_csv)){\n  # cache station metadata since timeout from Github Actions\n  stn_meta &lt;- ncdc_stations(\n    datasetid = \"GHCND\", \n    stationid = stn)\n  write_csv(stn_meta$data, stn_meta_csv)\n}\nread_csv(stn_meta_csv)\n\nif (!file.exists(stn_csv)){\n\n  date_beg &lt;- stn_meta$data$mindate\n  date_end &lt;- stn_meta$data$maxdate\n  max_rows &lt;- 1000\n  vars     &lt;- c(\"PRCP\",\"TMIN\",\"TMAX\")\n  \n  n_vars     &lt;- length(vars)\n  days_batch &lt;- floor(max_rows / n_vars)\n  dates &lt;- unique(c(\n    seq(\n      ymd(date_beg), \n      ymd(date_end), \n      by = glue(\"{days_batch} days\")),\n    ymd(date_end)))\n  \n  n_i &lt;- length(dates) - 1\n  for (i in 1:n_i){\n    # for (i in 14:n_i){\n    date_beg &lt;- dates[i]\n    if (i == n_i){\n      date_end &lt;- dates[i+1]\n    } else {\n      date_end &lt;- dates[i+1] - days(1)\n    }\n    print(glue(\"{i} of {n_i}: {date_beg} to {date_end}  ~  {Sys.time()}\"))\n    \n    # retry if get Error: Service Unavailable (HTTP 503)\n    o           &lt;- NULL\n    attempt     &lt;- 1\n    attempt_max &lt;- 10\n    while (is.null(o) && attempt &lt;= attempt_max) {\n      if (attempt &gt; 1)\n        print(glue(\"  attempt {attempt}\", .trim = F))\n      attempt &lt;- attempt + 1\n      try(\n        o &lt;- ncdc(\n          datasetid  = \"GHCND\", \n          stationid  = stn, \n          datatypeid = vars, \n          startdate  = date_beg,\n          enddate    = date_end,\n          limit      = max_rows) )\n    }\n    \n    if (i == 1) {\n      df &lt;- o$data\n    } else {\n      df &lt;- rbind(df, o$data)\n    }\n  }\n  stopifnot(duplicated(df[,1:2])|&gt; sum() == 0)\n  \n  df &lt;- df |&gt; \n    mutate(\n      date     = as.Date(strptime(\n        date, \"%Y-%m-%dT00:00:00\")),\n      datatype = recode(\n        datatype, \n        PRCP = \"precip_mm\", \n        TMIN = \"temp_c_min\", \n        TMAX = \"temp_c_max\"),\n      value    = value / 10) |&gt; \n    select(\n      -station, # station         : all \"GHCND:USW00012842\"\n      -fl_m,    # measurement flag: 3,524 are \"T\" for trace\n      -fl_t,    # time        flag: all \"2400\"\n      -fl_q)    # quality     flag: all \"\"\n  \n  write_csv(df, stn_csv)\n}\n\nd &lt;- read_csv(stn_csv)\n\nd |&gt; \n  select(date, datatype, value) |&gt;\n  filter(datatype %in% c(\"temp_c_min\",\"temp_c_max\")) |&gt;\n  pivot_wider(\n    names_from  = datatype, \n    values_from = value) |&gt;\n  dygraph(main = \"Daily Temperature (ºC)\") |&gt; \n  dyOptions(\n    colors = brewer.pal(5, \"YlOrRd\")[c(5,3)]) |&gt; \n  dySeries(\"temp_c_min\", label = \"min\") |&gt; \n  dySeries(\"temp_c_max\", label = \"max\")\n\nd |&gt; \n  select(date, datatype, value) |&gt;\n  filter(datatype %in% c(\"precip_mm\")) |&gt;\n  pivot_wider(\n    names_from  = datatype, \n    values_from = value) |&gt;\n  dygraph(main = \"Daily Precipitation (mm)\") |&gt; \n  dySeries(\"precip_mm\", label = \"precip\")\n\n\nTODO: - trend analysis. e.g. NOAA’s Climate at a Glance. Typically based on the last 30 years, but here we’ve got back to 1939-02-01 so almost 100 years. Keep it 5 years and see how rate changing over time.\n\nsevere weather events? “Sea-level rise exponentially increases coastal flood frequency Mohsen taherkhani”\n\n\n\n2.2.1.2 Satellite",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#precipitation",
    "href": "data.html#precipitation",
    "title": "2  Data",
    "section": "2.3 Precipitation",
    "text": "2.3 Precipitation\nMaterials:\n\n“RAIN AS A DRIVER” in tbep-os-presentations/state_of_the_bay_2023.qmd\nPrecipitation - NEXRAD QPE CDR | National Centers for Environmental Information (NCEI)\n\n\n\nCode\nlibrarian::shelf(\n  dplyr, here, leaflet,\n  # mapview, \n  readxl, sf, tbep-tech/tbeptools)\n# register with renv\nlibrary(dplyr)\nlibrary(here)\nlibrary(leaflet)\n# library(mapview)\nlibrary(readxl)\nlibrary(sf)\nlibrary(tbeptools)\n\n# from SWFWMD grid cells, use only if interested in areas finer than TB watershed\n# this currently gets the same data as the compiled spreadsheet\ngrd &lt;- st_read(here('../tbep-os-presentations/data/swfwmd-GARR-gisfiles-utm/swfwmd_pixel_2_utm_m_83.shp'), quiet = T)\n# mapView(grd)\n\ntbgrdcent &lt;- grd %&gt;%\n  st_transform(crs = st_crs(tbshed)) %&gt;%\n  st_centroid() %&gt;%\n  .[tbshed, ]\n\n# unzip folders\nloc &lt;- here('../tbep-os-presentations/data/swfwmd_rain')\n# files &lt;- list.files(loc, pattern = '.zip', full.names = T)\n# lapply(files, unzip, exdir = loc)\n\n# read text files\nraindat &lt;- list.files(loc, pattern = '19.*\\\\.txt$|20.*\\\\.txt$', full.names = T) %&gt;%\n  lapply(read.table, sep = ',', header = F) %&gt;%\n  do.call('rbind', .) %&gt;%\n  rename(\n    'PIXEL' = V1,\n    'yr' = V2,\n    'inches' = V3) %&gt;%\n  filter(PIXEL %in% tbgrdcent$PIXEL)\n\n# ave rain dat\nraindatave &lt;- raindat %&gt;%\n  summarise(\n    inches = mean(inches, na.rm = T),\n    .by = 'yr')\n\n##\n# use compiled SWFWMD data\n\n# # https://www.swfwmd.state.fl.us/resources/data-maps/rainfall-summary-data-region\n# # file is from the link \"USGS watershed\"\n# download.file(\n#   'https://www4.swfwmd.state.fl.us/RDDataImages/surf.xlsx?_ga=2.186665249.868698214.1705929229-785009494.1704644825',\n#   here('data/swfwmdrainfall.xlsx'),\n#   mode = 'wb'\n#   )\n\nraindatave_url &lt;- \"https://www4.swfwmd.state.fl.us/RDDataImages/surf.xlsx\"\ndir.create(here('data/swfwmd.state.fl.us'))\nraindatave_xl &lt;- here('data/swfwmd.state.fl.us/surf.xlsx')\n\ndownload.file(raindatave_url, raindatave_xl)\nread_excel(raindatave_xl)\n\ndownload.file(raindatave_url, here('data/swfwmdrainfall.xlsx'), mode = 'wb')\n\nraindatave &lt;- read_excel(\n  raindatave_xl, sheet = 'ann-usgsbsn', skip = 1) %&gt;% \n  filter(Year %in% 1975:2023) %&gt;% \n  select(\n    yr = Year, \n    inches = `Tampa Bay/Coastal Areas`\n  ) %&gt;% \n  mutate_all(as.numeric)\n\nraindatave_now &lt;- \nreadxl::read_excel()\n\nraindatave &lt;- read_excel(here('data/swfwmdrainfall.xlsx'), sheet = 'ann-usgsbsn', skip = 1) %&gt;% \n  filter(Year %in% 1975:2023) %&gt;% \n  select(\n    yr = Year, \n    inches = `Tampa Bay/Coastal Areas`\n  ) %&gt;% \n  mutate_all(as.numeric)\n\n# ave chldat\nchlave &lt;- anlz_avedat(epcdata) %&gt;% \n  .$ann %&gt;% \n  filter(var == 'mean_chla') %&gt;% \n  summarise(\n    chla = mean(val, na.rm = T),\n    .by = 'yr'\n  ) %&gt;% \n  filter(yr &gt;= 1975)\n  \ntoplo &lt;- inner_join(chlave, raindatave, by = 'yr')\n\np1 &lt;- ggplot(raindatave, aes(x = yr, y = inches)) +\n  geom_line() +\n  geom_point() +\n  geom_point(data = raindatave[chlave$yr == 2023, ], col = 'red', size = 2) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n  ) + \n  labs(\n    x = NULL, \n    y = 'Annual rainfall (inches)', \n    title = 'Annual rainfall', \n    subtitle = 'Tampa Bay watershed, 1975 - 2023'\n  )\n\np2 &lt;- ggplot(chlave, aes(x = yr, y = chla)) +\n  geom_line() +\n  geom_point() +\n  geom_point(data = chlave[chlave$yr == 2023, ], col = 'red', size = 2) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n  ) + \n  labs(\n    x = NULL, \n    y = 'Chlorophyll-a (ug/L)', \n    title = 'Annual mean chlorophyll-a', \n    subtitle = 'All segments, 1975 - 2023'\n  )\n\np3 &lt;- ggplot(toplo, aes(x = inches, y = chla)) +\n  geom_text_repel(aes(label = yr), point.size = NA, segment.size = NA) +\n  geom_label_repel(data = toplo[toplo$yr == 2023, ], aes(label = yr), color = 'red', point.size = NA) +\n  geom_smooth(formula = y ~ x, method = 'lm', se = F, color = 'red') + \n  # geom_segment(aes(x = 45, xend = 40, y = 4.86, yend = 4.86), color = 'red', arrow = arrow(length = unit(0.2, \"inches\")), linewidth = 1) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n  ) + \n  labs(\n    x = 'Annual rainfall (inches)', \n    y = 'Chlorophyll-a (ug/L)', \n    title = 'Annual mean chlorophyll-a vs. rainfall', \n    caption = 'Data from EPCHC, SWFWMD'\n  )\n\np &lt;- (p1 / p2) | p3\np\n\n\n\n2.3.1 rNOMADS\n\n\nCode\n# librarian::shelf(rNOMADS)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#prism",
    "href": "data.html#prism",
    "title": "2  Data",
    "section": "2.4 PRISM",
    "text": "2.4 PRISM\n\nHMS: Hydrologic Micro Services | United States Environmental Protection Agency | US EPA\n\n\nThe Parameter-elevation Relationship on Independent Slopes Model (PRISM) is a combined dataset consisting of ground gauge station and RADAR products. The data is on a 4km grid resolution covering the contiguous United States. Data is available from 1981 to present.PRISM data are reported in GMT (UTC). PRISM provides daily average temperature and dew-point temperature data. Relative humidity is calculated using a version of the August-Roche-Magnus equation as follows ): RH = 100*(EXP((17.625*TD)/(243.04+TD))/EXP((17.625*T)/(243.04+T))) where, RH is % relative humidity, TD is dew-point temperature (celsius), and T is air temperature (celsius).\n\n\nAHPS Precipitation Analysis\n\n“Normal” precipitation is derived from PRISM climate data, created at Oregon State University. The PRISM gridded climate maps are considered the most detailed, highest-quality spatial climate datasets currently available.\n\nprism R package\n\n\n\n\nParameter\nDescription\n\n\n\n\ntmin\nMinimum temperature\n\n\ntmax\nMaximum temperature\n\n\ntmean\nMean temperature (tmean == mean(tmin, tmax))\n\n\ntdmean\nMean dew point temperature\n\n\nppt\nTotal precipitation (rain and snow)\n\n\nvpdmin\nDaily minimum vapor pressure deficit\n\n\nvpdmax\nDaily maximum vapor pressure deficit\n\n\n\n\nData are at 4km resolution, except for the normals which can also be downloaded at 800m resolution.\n\nTemporal data availability:\n\nRecent\n1981 to present\ndaily, monthly, annual data\nHistorical\n1895 through 1980\ncomplete monthly and annual data by year\nNormals\n30-year normals daily, monthly, and annual normals, each as a single grid The 30 year PRISM normal from 1981-2010 is used for precipitation analysis since 2004. Prior to 2004 the 30 year PRISM normal from 1961-1990 is used.\nForms\n\nstable\nprovisional\nearly\n\n\n\nDaily data are considered “early” for the current month. The previous six months are provisional data. After six months data are considered stable. Thus early data only exist for daily data, while there can be monthly (and presumably yearly) provisional data. – ?prism::prism_archive_clean\n\n\n2.4.1 Example tbeptools::read_importprism()\n\n@example from tbeptools::read_importprism()\n\n\n\nCode\n# devtools::install_local(\"../tbeptools\", force = T)\n# devtools::load_all(\"../tbeptools\")\n\n# setup output directory and table\ndir_tif   &lt;- here::here(\"../tbeptools/inst/prism\")\nzonal_csv &lt;- file.path(dir_tif, \"_zones.csv\")\n\n# run function for Tampa Bay watersheds for first 3 days and 4 variables\nd &lt;- read_importprism(\n  vars      = c(\"tmin\", \"tmax\", \"tdmean\", \"ppt\"),\n  date_beg  = as.Date(\"1981-01-01\"),\n  date_end  = as.Date(\"1981-01-03\"),\n  dir_tif   = dir_tif,\n  sf_zones  = tbsegshed,\n  fld_zones = \"bay_segment\",\n  zonal_csv = zonal_csv)\n\n# plot first of output rasters\ntifs &lt;- list.files(dir_tif, pattern = \".tif$\", full.names = T)\nbasename(tifs)\nr &lt;- terra::rast(tifs[1])\nnames(r) # {data observed}_{variable}_v{version}_{date updated}\nterra::plet(\n  r[[3]],\n  main  = names(r)[3],\n  col   = \"Spectral\",\n  tiles = \"CartoDB.DarkMatter\")\n\n# show summary by zone\nd\n\n\n\n\n2.4.2 Operationalize\n\n\nCode\nlibrarian::shelf(\n  dplyr, here, sf, tbep-tech/tbeptools)\n\n# outputs\ndir_prism &lt;- here(\"data/prism\")\nprism_csv &lt;- here(\"data/prism.csv\")\n  \n# Tampa Bay watershed zones, including whole bay (\"TB\")\ntb_zones &lt;- tbsegshed |&gt;\n  bind_rows(\n    tbshed |&gt;\n      mutate(bay_segment = \"TB\") |&gt;\n      select(bay_segment, geometry))\n\n# bounding box with 0.2º margin around watershed, rounded to .1\nbb &lt;- tbshed |&gt; \n  st_buffer(0.2) |&gt; \n  st_bbox() |&gt; \n  round(1)\n#     c(xmin = -82.9, ymin = 27.4, xmax = -81.9, ymax = 28.4)\n# after running terra::trim() on raster:\nbb &lt;- c(xmin = -82.9, ymin = 27.2, xmax = -81.7, ymax = 28.6)\n\nd &lt;- read_importprism(\n  vars      = c(\"tmin\", \"tmax\", \"tdmean\", \"ppt\"),\n  date_beg  = as.Date(\"1981-01-01\"),\n  date_end  = Sys.Date(),\n  bbox      = bb,\n  dir_tif   = dir_prism,\n  sf_zones  = tb_zones,\n  fld_zones = \"bay_segment\",\n  zonal_csv = prism_csv,\n  verbose   = T)\n\n# show summary by zone\nd\n\n\nTODO: Github Action on daily cron to run read_importprism() for all days and variables\n\n\nCode\n# Get monthly (every month) and annual 30-year normals for precipitation\n\n# get_prism_normals(\n\n# type = \"ppt\",\n\n# resolution = \"800m\",\n\n# mon = 1:12,\n\n# annual = TRUE,\n\n# keepZip = FALSE)\n\nvar    &lt;- \"tmax\"\nperiod &lt;- \"daily\"\ndate   &lt;- today() - days(1) # yesterday\n\nget_prism_dailys(\n  type    = \"tmax\", \n  dates   = date, \n  keepZip = F)\n\npd &lt;- prism_archive_subset(var, period, dates = date)\npd_image(pd, col=\"redblue\")\nr &lt;- pd_stack(pd) |&gt; \n  rast()\nplot(r)\n\nlibrary(leaflet)\nr_3857 &lt;- projectRasterForLeaflet(\n  r, method = \"bilinear\")\npal &lt;- colorNumeric(\n  \"Spectral\",  values(r_3857, na.rm=T), \n  na.color = \"transparent\")\n\nleaflet() |&gt;\n  addProviderTiles(\n    providers$CartoDB.Positron) |&gt;\n  addRasterImage(\n    r_3857, opacity = 0.7) |&gt; \n  addPolygons(\n    data = tbsegshed, \n    fillOpacity = 0, \n    color = \"purple\", weight = 5)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#assign-bounding-box-for-aoi-cropping-of-rasters",
    "href": "data.html#assign-bounding-box-for-aoi-cropping-of-rasters",
    "title": "2  Data",
    "section": "2.5 Assign bounding box for AoI cropping of rasters",
    "text": "2.5 Assign bounding box for AoI cropping of rasters\n\n\nCode\n# tbshed_pd &lt;- tbshed |&gt; \nr &lt;- pd_stack(prism_archive_subset(\"tmax\", \"daily\")[1])\ncrs &lt;- crs(r, proj=T)  # +proj=longlat +datum=NAD83 +no_defs\ntbshed_pd &lt;- tbsegshed |&gt; \n  st_transform()\n\nsf_use_s2(F)\ntbshed_buf &lt;- tbshed_pd |&gt; \n  st_union() |&gt; \n  st_make_valid() |&gt; \n  st_buffer(0.2) |&gt; \n  st_bbox() |&gt; \n  st_as_sfc() |&gt; \n  st_as_sf()\n\nbb &lt;- st_bbox(tbshed_buf) |&gt; round(1)\n# xmin  ymin  xmax  ymax \n# -83.1  27.2 -81.7  28.6\nbb &lt;- c(xmin = -83.1, ymin = 27.2, xmax = -81.7, ymax = 28.6)\nply_bb &lt;- st_bbox(bb, crs = crs(r, proj=T)) |&gt; \n  st_as_sfc() |&gt; \n  st_as_sf()\n\nleaflet() |&gt; \n  addProviderTiles(providers$Stadia.StamenTonerLite) |&gt; \n  addPolygons(data = ply_bb, color=\"green\") |&gt; \n  addPolygons(data = tbshed_pd)\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(furrr) # install.packages(\"furrr\")\nlibrary(glue)\nlibrary(here)\nlibrary(lubridate)\nlibrary(prism)\nlibrary(purrr)\nlibrary(sf)\nlibrary(terra)\n\nn_cores &lt;- parallel::detectCores() - 1\nplan(multisession, workers = n_cores)\n\nprism_archive_crop &lt;- function(\n  type, temp_period, ...,\n  bb  = c(xmin = -82.9, ymin = 27.2, xmax = -81.7, ymax = 28.6),\n  crs = \"+proj=longlat +datum=NAD83 +no_defs\", # WRONG: \"+proj=longlat +ellps=GRS80 +no_defs\"\n  verbose = F){\n\n  ply_bb &lt;- sf::st_bbox(bb, crs = crs) |&gt; \n    sf::st_as_sfc() |&gt; \n    sf::st_as_sf()\n  \n  pds &lt;- prism::prism_archive_subset(type, temp_period, ...)\n  \n  for (i in 1:length(pds)){ # i = 1\n    r &lt;- prism::pd_stack(pds[i]) |&gt; \n      terra::rast()\n    \n    is_cropped &lt;- all(sf::st_bbox(r) |&gt; round(1) == bb)\n    if (!is_cropped){\n      r_bil &lt;- terra::sources(r)\n      r_bb &lt;- terra::crop(r, ply_bb, mask = T, touches = T) |&gt;\n        terra::trim()\n      terra::writeRaster(r_bb, r_bil, filetype = \"EHdr\", overwrite = T)\n      \n      bb_cropped &lt;- sf::st_bbox(r_bb) |&gt; round(1)\n      if (!all(bb_cropped == bb))\n        warning(glue(\n          \"bbox of clipped raster rounded to 1 decimal:\n              {paste(bb_cropped, collapse=', ')}\n           does not match input argument `bb`:\n              {paste(bb, collapse=', ')}\"))\n    }\n  }\n}\n\nyrs  &lt;- 1981:year(now())\nmos  &lt;- 1:12\nvars &lt;- c(\"tmin\", \"tmax\", \"tdmean\", \"ppt\")  \n# skipping: \"tmean\" [avg(tmin,tmax)], vapor pressure [\"vpdmin\", \"vpdmax\"]\n\n# ((today() - days(1)) - date(\"1981-01-01\")) |&gt; as.integer() * length(vars) # 63,304 dirs expected in tmp/prism\nn_dirs &lt;- fs::dir_ls(here::here(\"tmp/prism\"), type = \"directory\") |&gt; length()\nmessage(glue::glue(\"{n_dirs} ~ {Sys.time()}\"))\n# 1540 ~ 2024-05-02 18:28:41.717828\n# 2527 ~ 2024-05-02 18:46:32.97783\n# 3357 ~ 2024-05-02 18:59:52.753584\nn_all &lt;- 63304\n\nn1 &lt;- 1540\nt1 &lt;- parse_date_time(\n    \"2024-05-02 18:28:41.717828\", \"Ymd HMS\")\nn2 &lt;- 3357\nt2 &lt;- parse_date_time(\n    \"2024-05-02 18:59:52.753584\", \"Ymd HMS\")\n\ndt &lt;- difftime(t2, t1, units = \"secs\") |&gt; as.integer()\ndn &lt;- n2 - n1\nn_togo &lt;- n_all - n2\neta &lt;- t2 + seconds(dn / dt * n_togo)\nmessage(glue::glue(\"ETA: {eta}\"))\n# ETA: 2024-05-03 10:20:03.1543\n# ETA: 2024-05-03 11:10:09.588966\n\nprism_set_dl_dir(here::here(\"tmp/prism\"))\n\nyesterday &lt;- today() - days(1)\n\nd_ymv = tibble(\n  yr = yrs) |&gt; \n  cross_join(\n    tibble(mo = mos)) |&gt; \n  cross_join(\n    tibble(var = vars)) |&gt; \n  mutate(\n    date_beg = map2_chr(yr, mo, \\(yr, mo){\n      date(glue(\"{yr}-{mo}-01\")) |&gt; \n        as.character() }),\n    date_end = map_chr(date_beg, \\(date_beg){\n      # date_beg &lt;- \"2024-05-01\"\n      date_end &lt;- (date(date_beg) + months(1)) - days(1)\n      if (date_end &gt; yesterday)\n        date_end &lt;- yesterday\n      date_end |&gt; \n        as.character()\n    }) ) |&gt; \n  filter(date(date_beg) &lt;= yesterday) |&gt; \n  arrange(date_beg, date_end, var) |&gt; \n  select(date_beg, date_end, var) |&gt; \n  # filter(date(date_beg) &gt;= date(\"1981-03-01\")) |&gt; \n  # rstudio.marinesensitivity.org:\n  # filter(\n  #   date(date_beg) &gt;= date(\"1981-09-01\"),\n  #   date(date_end) &lt;  date(\"1986-07-01\")) # |&gt; \n  # laptop:\n  # filter(\n  #   date(date_beg) &gt;= date(\"1986-12-01\")) # |&gt;\n  mutate(\n    n_files = pmap_int(list(\n      date_beg = date_beg,\n      date_end = date_end,\n      var      = var), \\(date_beg, date_end, var){\n        prism::prism_archive_subset(\n          var, \"daily\",\n          minDate = date_beg,\n          maxDate = date_end) |&gt;\n          length() }),\n    n_days = map2_int(date_beg, date_end, \\(date_beg, date_end){\n      difftime(date(date_end), date(date_beg), units = \"days\") |&gt;\n        as.integer() }),\n    pct_done = n_files / n_days)\n\nprism_csv &lt;- here(\"tmp/prism.csv\")\nreadr::write_csv(d_ymv, prism_csv)\n\n# TODO: delete all extraneous station files\n# find . -name \"*_bil.stn.csv\" -type f -delete\n\n# TODO: on server remove dir \n# dir='PRISM_ppt_provisional_4kmD2_20231101_bil'\n# re='PRISM_(.*)_(.*)_(.*)_(.*)_bil'\n# [[ $dir =~ $re ]] && date=\"${BASH_REMATCH[4]}\" && echo \"date: $date for $dir\"\n# var=${dir//$re/\\1}\n# type=${dir//$re/\\2}\n# res=${dir//$re/\\3}\n# date=${dir//$re/\\4}\n\nfuture_pmap(d_ymv, \\(date_beg, date_end, var){\n\n  prism_set_dl_dir(here::here(\"tmp/prism\"))\n  \n  # fetch PRISM national rasters\n  get_prism_dailys(\n    type    = var, \n    minDate = date_beg,\n    maxDate = date_end,\n    keepZip = F)\n  \n  # remove any duplicates: stable &gt; provisional &gt; early\n  prism_archive_clean(\n    var, \"daily\", \n    minDate = date_beg,\n    maxDate = date_end)\n  \n  # trim rasters to bounding box\n  prism_archive_crop(\n    var, \"daily\", \n    minDate = date_beg,\n    maxDate = date_end)\n})\n\n# clear future processes\nif (!inherits(plan(), \"sequential\")) plan(sequential)\n\n\n\n\nCode\nprism_set_dl_dir(here::here(\"tmp/prism\"))\n\nfor (var in vars)\n  prism_archive_crop(var, \"daily\")\n\n\n\n\nCode\nlibrary(furrr) # install.packages(\"furrr\")\n\nn_cores &lt;- parallel::detectCores() - 1\nplan(multisession, workers = n_cores)\n\ndir_prism &lt;- here::here(\"tmp/prism\")\nprism_set_dl_dir(dir_prism)\nvars      &lt;- c(\"tmin\", \"tmax\", \"tdmean\", \"ppt\")\ndates_all &lt;- (date(\"1981-01-01\"):(today() - days(1))) |&gt; as.Date()\n\nrx   &lt;- \"PRISM_(.*)_(.*)_(.*)_(.*)_bil\"\nd_done &lt;- tibble()\nfor (var in vars){ # var &lt;- vars[4]\n  \n  pds &lt;- prism::prism_archive_subset(type = var, temp_period = \"daily\")\n\n  d_var &lt;- tibble(\n    pd = pds) |&gt; \n    mutate(\n      var   = str_replace(pd, rx, \"\\\\1\"),\n      class = str_replace(pd, rx, \"\\\\2\"),\n      date  = str_replace(pd, rx, \"\\\\4\") |&gt; \n        as.Date(format = \"%Y%m%d\") ) \n  \n  if (nrow(d_done) == 0){\n    d_done &lt;- d_var\n  } else {\n    d_done &lt;- d_done |&gt; \n      bind_rows(d_var)\n  }\n}\n# table(d_done$var)\n#    ppt tdmean   tmax   tmin \n#  15759  15807  15746  15805\n\nd_todo &lt;- tibble(\n  var = vars) |&gt; \n  cross_join(tibble(\n    date = dates_all)) |&gt; \n  anti_join(\n    d_done |&gt; \n      select(var, date),\n    by = c(\"date\", \"var\"))\n  \nprism_dates_crop &lt;- function(\n    var, \n    dates, \n    dir_prism = here::here(\"tmp/prism\")){\n  # var = \"tmin\"; dates = date(\"2024-05-01\"); dir_prism = here::here(\"tmp/prism\")\n  # PRISM_tmin_early_4kmD2_20240509_bil\n  # ls -l | grep -v stable | grep -v provisional | tail\n  # ls -l | grep tmin_stable      | head : PRISM_tmin_stable_4kmD2_19810101_bil\n  # ls -l | grep tmin_stable      | tail : PRISM_tmin_stable_4kmD2_20231031_bil\n  # ls -l | grep tmin_provisional | head : PRISM_tmin_provisional_4kmD2_20231101_bil\n  # ls -l | grep tmin_provisional | tail : PRISM_tmin_provisional_4kmD2_20240430_bil\n  # ls -l | grep tmin_early       | head : PRISM_tmin_early_4kmD2_20240501_bil\n  # ls -l | grep tmin_early       | tail : PRISM_tmin_early_4kmD2_20240509_bil\n  # rm -r PRISM_tmin_stable_4kmD2_19810101_bil \\\n  #       PRISM_tmin_stable_4kmD2_20231031_bil \\\n  #       PRISM_tmin_provisional_4kmD2_20231101_bil \\\n  #       PRISM_tmin_provisional_4kmD2_20240430_bil \\\n  #       PRISM_tmin_early_4kmD2_20240501_bil \\\n  #       PRISM_tmin_early_4kmD2_20240509_bil\n  # prism_dates_crop(\n  #   \"tmin\", \n  #   c(\"1981-01-01\",\"2023-10-31\", \"2023-11-01\", \"2024-04-30\", \"2024-05-01\") # , \"2024-05-09\"))\n\n  prism_set_dl_dir(dir_prism)\n  \n  # fetch PRISM national rasters\n  # get_prism_dailys(\n  #   type    = var,\n  #   dates   = dates,\n  #   keepZip = F)\n    \n  # remove any duplicates: stable &gt; provisional &gt; early\n  prism_archive_clean(\n    type        = var, \n    temp_period = \"daily\", \n    dates       = dates)\n  \n  # bil &lt;- prism_archive_subset(\n  #   type        = var,\n  #   temp_period = \"daily\",\n  #   dates       = dates) |&gt;\n  #   pd_to_file()\n  # crs_r &lt;- rast(bil) |&gt; crs(proj=T) \n  # message(paste(glue(\"{basename(bil)}: {crs_r}\"),\"\\n\"))\n  # early (PRISM_tmin_early_4kmD2_20240509_bil):\n  #   \"+proj=longlat +datum=NAD83 +no_defs\"\n\n  # trim rasters to bounding box\n  prism_archive_crop(\n    type        = var,\n    temp_period = \"daily\",\n    dates       = dates)\n}\n\nprism_dates_crop(\n  \"tmin\",\n  c(\"1981-01-01\",\"2023-10-31\", \"2023-11-01\", \"2024-04-30\", \"2024-05-01\")) # , \"2024-05-09\"))\n\n\n# 20240430_bil\n# ls -l | grep -v stable | grep -v provisional | tail\n\nd_todo |&gt; \n  # future_pmap(prism_dates_crop)\n  pmap(prism_dates_crop)\n\nvar  &lt;- vars[1] # TODO: loop all vars\n # check only one crs and bb\ntable(d_bils$crs)\ntable(d_bils$bb)\n    \n# save daily climatologies ----\nlibrarian::shelf(\n  fs)\n\nrx   &lt;- \"PRISM_(.*)_(.*)_(.*)_(.*)_bil\"\nd_bils &lt;- tibble(\n  path = dir_ls(dir_prism, glob = \"*.bil\", recurse = T)) |&gt; \n  mutate(\n    pd    = basename(path_bil) |&gt; path_ext_remove(),\n    var   = str_replace(pd, rx, \"\\\\1\"),\n    class = str_replace(pd, rx, \"\\\\2\"),\n    date  = str_replace(pd, rx, \"\\\\4\") |&gt; \n        as.Date(format = \"%Y%m%d\"),\n    md    = format(date, \"%m-%d\"))\n\ncrs = \"+proj=longlat +datum=NAD83 +no_defs\"\nbb  = c(xmin = -82.9, ymin = 27.2, xmax = -81.7, ymax = 28.6)\nply_bb &lt;- st_bbox(bb, crs = crs(r, proj=T)) |&gt; \n  st_as_sfc() |&gt; \n  st_as_sf()\n\nd_bils |&gt; \n  arrange(md, date, var) |&gt;  # order by: month-day, date, variable\n  select(md, path) |&gt; \n  group_by(md) |&gt; \n  nest(paths = path) |&gt; \n  ungroup() |&gt; \n  filter(md == \"01-01\") |&gt; \n  # pull(md) %&gt;% .[92]\n  # slice(91:93) |&gt; \n  pwalk(\\(md, paths){\n    \n    if (md == \"01-01\")\n      browser()\n    r_tif &lt;- here(glue(\"tmp/daily/prism_daily_{md}.tif\"))\n    if (file.exists(r_tif)){\n      message(glue(\"{basename(r_tif)} exists, skipping\"))\n      return(NA)\n    }\n    \n    message(glue(\"{basename(r_tif)} building\"))\n    paths |&gt; \n      mutate(\n        ext = map_chr(\n          path, \\(p){ \n            ext(rast(p)) |&gt; as.vector() |&gt; round(1) |&gt; \n              paste(collapse=\",\") } ) ) |&gt; \n      filter(ext == \"-125,-66.5,24.1,49.9\") |&gt; \n      select(path) |&gt;  #  |&gt; basename()\n      # [1] \"PRISM_tdmean_stable_4kmD2_19920401_bil.bil\"\n      # [2] \"PRISM_tdmean_stable_4kmD2_19960401_bil.bil\"\n      # [3] \"PRISM_ppt_stable_4kmD2_20030401_bil.bil\" \n      pwalk(\\(path){\n        r &lt;- terra::rast(path)\n        r_bb &lt;- terra::crop(r, ply_bb, mask = T, touches = T) |&gt;\n          terra::trim()\n        tmp &lt;- tempfile(tempdir(), fileext = \".bil\")\n        dir.create(dirname(tmp), recursive = T, showWarnings = F)\n        terra::writeRaster(x = r_bb, filename = tmp, filetype = \"EHdr\", overwrite = T)\n        terra::writeRaster(rast(tmp), path, filetype = \"EHdr\", overwrite = T)\n      })\n    \n    r &lt;- rast(unlist(paths))\n    crs(r) &lt;- \"+proj=longlat +datum=NAD83 +no_defs\"\n    terra::writeRaster(\n      r, r_tif, \n      datatype = \"FLT4S\",\n      filetype = \"GTiff\", gdal = c(\"COMPRESS=DEFLATE\"),\n      overwrite = T)\n  })\n\n# Yay: avg filesize = 0.5 MB * 365/6 (leap day) = 179 MB\n\nr &lt;- rast(r_tif)\nd_r &lt;- tibble(pd = names(r)) |&gt; \n  mutate(\n    var   = str_replace(pd, rx, \"\\\\1\"),\n    class = str_replace(pd, rx, \"\\\\2\"),\n    date  = str_replace(pd, rx, \"\\\\4\") |&gt; \n      as.Date(format = \"%Y%m%d\") ) \n\nlength(names(r)) # 176\nplet(r[[100]], tiles=providers$CartoDB.DarkMatter)\n\n\n\n\nCode\nlibrarian::shelf(\n  dplyr, fs, glue, here, lubridate, purrr, sf, stringr, terra, tibble, tidyr)\n\ndir_daily &lt;- here::here(\"data/prism\")\n# https://services.nacse.org/prism/data/public/4km/ppt/20240512\nvars      &lt;- c(\"tmin\", \"tmax\", \"tdmean\", \"ppt\")\nprism_beg &lt;- lubridate::date(\"1981-01-01\")\n# yesterday &lt;- lubridate::today(tzone = \"UTC\") - lubridate::days(1)\n# accommodate up to 12 hrs to publish yesterday\nyesterday_tz &lt;- \"Etc/GMT+12\"\nyesterday &lt;- lubridate::today(tzone = yesterday_tz) - lubridate::days(1)\ndates_all &lt;- (prism_beg:(yesterday)) |&gt; as.Date()\n\nrx_tif &lt;- \"prism_daily_([0-9]{2})-([0-9]{2}).tif\"\nrx_lyr &lt;- \"PRISM_(.*)_(.*)_(.*)_(.*)_bil\"\n\nd_done &lt;- tibble::tibble(\n  tif_path = list.files(dir_daily, \".*\\\\.tif$\", full.names = T),\n  tif  = basename(tif_path),\n  tif_md   = stringr::str_replace(tif, rx_tif, \"\\\\1-\\\\2\"),\n  tif_mo   = stringr::str_replace(tif, rx_tif, \"\\\\1\"),\n  tif_day  = stringr::str_replace(tif, rx_tif, \"\\\\2\") ) |&gt; \n  dplyr::mutate(\n    lyr = purrr::map(tif_path, \\(tif_path) terra::rast(tif_path) |&gt; names() ) ) |&gt; \n  tidyr::unnest(lyr) |&gt; \n  dplyr::mutate(\n    lyr_var       = stringr::str_replace(lyr, rx_lyr, \"\\\\1\"),\n    lyr_stability = stringr::str_replace(lyr, rx_lyr, \"\\\\2\"),\n    lyr_date      = stringr::str_replace(lyr, rx_lyr, \"\\\\4\") |&gt; \n        as.Date(format = \"%Y%m%d\")) |&gt; \n  dplyr::arrange(tif_md, lyr_date, lyr_var) # order by: month-day, date, variable\n  \n# define expected stability by date\nearly_end  &lt;- lubridate::today(tzone = \"UTC\") - lubridate::days(1)\nearly_beg  &lt;- lubridate::ym(glue::glue(\"{lubridate::year(early_end)}-{lubridate::month(early_end)}\"))\nprov_end   &lt;- early_beg - days(1)\nprov_beg   &lt;- early_beg - months(6)\nstable_end &lt;- prov_beg - days(1)\nstable_beg &lt;- prism_beg\n# early:       2024-05-01 to 2024-05-06 (this month)\n# provisional: 2023-11-01   to 2024-04-30 (previous 6 months)\n# stable:      1981-01-01 to 2023-10-31 (before 6 months)\n\nd_todo &lt;- tibble::tibble(\n  lyr_var = vars |&gt; sort()) |&gt; \n  dplyr::cross_join(\n    tibble::tibble(\n      lyr_date = dates_all) |&gt; \n      dplyr::mutate(\n        lyr_stability = cut(\n          lyr_date,\n          breaks = c(stable_beg, stable_end, prov_beg, prov_end, early_beg, early_end),\n          labels = c(\"stable\", \"stable\", \"provisional\", \"provisional\", \"early\"),\n          include.lowest = T) ) ) |&gt; \n  dplyr::anti_join(\n    d_done |&gt; \n      dplyr::select(lyr_date, lyr_var, lyr_stability) |&gt; \n      dplyr::arrange(lyr_date, lyr_var, lyr_stability),\n    by = c(\"lyr_date\", \"lyr_var\", \"lyr_stability\")) |&gt; \n  dplyr::arrange(lyr_date, lyr_var, lyr_stability)\n\n# 1 ppt     2024-05-07 early\n\nprism_rast_parameters &lt;- function(r){\n  # convert raster names to data frame with components\n  \n  rx &lt;- \"PRISM_(.*)_(.*)_(.*)_(.*)_bil\"\n  \n  tibble::tibble(\n    idx = 1:terra::nlyr(r),\n    lyr = names(r)) |&gt; \n    mutate(\n      var       = stringr::str_replace(lyr, rx, \"\\\\1\"),\n      stability = stringr::str_replace(lyr, rx, \"\\\\2\"),\n      date      = stringr::str_replace(lyr, rx, \"\\\\4\") |&gt; \n        as.Date(format = \"%Y%m%d\"))\n}\n\nprism_get_daily &lt;- function(\n    var, date, \n    dir_daily = here::here(\"data/prism\"),\n    crs_proj  = \"+proj=longlat +datum=NAD83 +no_defs\",\n    bb        = c(xmin = -82.9, ymin = 27.2, xmax = -81.7, ymax = 28.6)){\n\n  u &lt;- glue::glue(\"https://services.nacse.org/prism/data/public/4km/{var}/{format(date, '%Y%m%d')}\")\n\n  ply_bb &lt;- sf::st_bbox(bb, crs = crs_proj) |&gt; \n    sf::st_as_sfc() |&gt; \n    sf::st_as_sf()\n  \n  # date = as.Date(\"1981-01-01\"); var = \"tdmean\"\n  z &lt;- glue::glue(\"{dir_daily}/temp_{date}_{var}.zip\")\n  message(glue::glue(\"Downloading PRISM daily {date} {var}\"))\n  download.file(u, z, quiet = T)\n  \n  # If downloaded zip &lt; 1 KB, assume one of these errors:\n  # - You have tried to download the file PRISM_tdmean_stable_4kmD2_19810101_bil.zip more than twice in one day (Pacific local time).  Note that repeated offenses may result in your IP address being blocked.\n  # - Invalid date: 20240513&lt;/br&gt;Valid day ranges for the given month are 1 to 12 [real reason: requesting beyond available date, ie not yet published]\n  if (file.size(z) &lt; 1000)\n    stop(readLines(z, warn=F))\n  \n  dir_z &lt;- fs::path_ext_remove(z)\n  dir.create(dir_z, showWarnings = F)\n  unzip(z, exdir = dir_z)\n  unlink(z)\n  \n  r_new &lt;- list.files(dir_z, \"PRISM_.*_bil\\\\.bil$\", full.names = T) |&gt; \n    # file.exists()\n    terra::rast() |&gt; \n    terra::crop(ply_bb, mask = T, touches = T) |&gt;\n    terra::trim()\n  terra::crs(r_new) &lt;- crs_proj\n  \n  md_tif &lt;- sprintf(\"%s/prism_daily_%02d-%02d.tif\", dir_daily, month(date), day(date))\n\n  if (!file.exists(md_tif)){\n    terra::writeRaster(\n        r_new, md_tif, \n        datatype = \"FLT4S\",\n        filetype = \"GTiff\", gdal = c(\"COMPRESS=DEFLATE\"),\n        overwrite = T)\n    dir_delete(dir_z)\n    return(T)\n  }\n  \n  r_md  &lt;- rast(md_tif)\n  df_md &lt;- prism_rast_parameters(r_md)\n  \n  # remove old date-var, eg for stability improved\n  i_lyr_rm &lt;- df_md |&gt; \n    filter(\n      date == !!date,\n      var  == !!var) |&gt; \n    pull(idx)\n  if (length(i_lyr_rm) &gt; 0)\n    r_md &lt;- terra::subset(r_md, i_lyr_rm, negate = T)\n\n  # combine old and new\n  r_md &lt;- c(r_md, r_new)\n  \n  # write out\n  tmp &lt;- tempfile(fileext = \".tif\")\n  terra::writeRaster(\n    r_md, tmp,\n    datatype = \"FLT4S\",\n    filetype = \"GTiff\", gdal = c(\"COMPRESS=DEFLATE\"),\n    overwrite = T)\n  terra::writeRaster(\n    rast(tmp), md_tif, \n    datatype = \"FLT4S\",\n    filetype = \"GTiff\", gdal = c(\"COMPRESS=DEFLATE\"),\n    overwrite = T)\n  fs::dir_delete(dir_z)\n  unlink(tmp)\n  return(T)\n}\n\nmsg &lt;- ifelse(\n  nrow(d_todo) &gt; 0,\n  glue::glue(\"Summary: {nrow(d_todo)} variable-dates {paste(range(d_todo$lyr_date), collapse=' to ')} to download and crop \"),\n  glue::glue(\"Summary: up to date as of yesterday ({yesterday_tz}): {yesterday}\"))\nmessage(msg)\n\nd_todo |&gt; \n  select(var = lyr_var, date = lyr_date) |&gt; \n  pwalk(prism_get_daily)\n\n\n# early:       2024-05-01 to 2024-05-06\n# provisional: 2023-11-01   to 2024-04-30\n# stable:      1981-01-01 to 2023-10-31\n# https://prism.nacse.org/documents/PRISM_downloads_web_service.pdf\n# PRISM_&lt;var&gt;_&lt;stability&gt;_&lt;scale&version&gt;_&lt;time period&gt;[_all|_annual]_bil.zip\n# https://services.nacse.org/prism/data/public/4km/&lt;element&gt;/&lt;date&gt;&lt;?format=[nc|asc|grib2]&gt;\n# https://services.nacse.org/prism/data/public/4km/tmin/20090405\n# https://prism.oregonstate.edu/documents/PRISM_update_schedule.pdf\n\n# dates &lt;- gen_dates(minDate = minDate, maxDate = maxDate, dates = dates)\ndates &lt;- date(\"2024-05-12\")\n# prism:::prism_vars() |&gt; sort()\nservice &lt;- \"http://services.nacse.org/prism/data/public/4km\"\ntype = \"ppt\"\nuri_dates &lt;- gsub(pattern = \"-\",replacement = \"\",dates)\n# uris &lt;- prism:::gen_prism_url(uri_dates, type, service)\nuris &lt;- paste(service, type, dates, sep = \"/\")\n# \"http://services.nacse.org/prism/data/public/4km/ppt/2024-05-12\"\n\nx &lt;- httr::HEAD(uris[1])\nfn &lt;- x$headers$`content-disposition`\nfn &lt;- regmatches(fn,regexpr('\\\\\"[a-zA-Z0-9_\\\\.]+',fn))\nfn &lt;- substr(fn,2,nchar((fn)))\nfn &lt;- gsub(\"provisional|early\", \"stable\", fn)\nfile_names &lt;- stringr::str_replace(\n  fn, \n  \"[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]\", \n  uri_dates\n)\nto_download_lgl &lt;- prism_check(file_names, lgl = TRUE)\nuris &lt;- uris[to_download_lgl]\n\nget_prism_dailys &lt;- function(type, minDate = NULL, maxDate =  NULL, \n                             dates = NULL, keepZip = TRUE, check = \"httr\",\n                             service = NULL)\nPRISM datasets:\n\nAN - Daily Time Series (AN81d/AN91d) Climate elements: tmin, tmax, tmean (derived), tdmean, ppt, vpdmin, vpdmax Units and scaling: tmin, tmax, tmean, tdmean (deg C); ppt (mm); vpdmin, vpdmax (hPa); all values are floating point Description: Daily dataset covering the conterminous US, starting on 1 January 1981 and ending yesterday.\n\nPRISM_update_schedule:\n\nasdf &gt; The PRISM map sequence is first updated to include a particular day about 24 hours after it has ended (Grid Count = 1). &gt; Note that a “PRISM Day” is defined as the 24-hour period ending at 1200 UTC on that day, e.g., a grid for July 2 covers the period 1200 UTC July 1 – 1200 UTC July 2\nasdf &gt; A second update (Grid Count = 2) is made after five days have elapsed; the five-day milestone was chosen because a large amount of new station data is typically received at this point.\n\n\n\nThe third update (Grid Count = 3) is produced during what is termed the “monthly update,” which is typically completed on about the 15th of the following month.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#map-swipe-yesterday-vs-climatology",
    "href": "data.html#map-swipe-yesterday-vs-climatology",
    "title": "2  Data",
    "section": "2.6 Map Swipe Yesterday vs Climatology",
    "text": "2.6 Map Swipe Yesterday vs Climatology\n\n\nCode\nprism_set_dl_dir(here::here(\"tmp/prism\"))\n\nvar = \"tmax\"\ndate &lt;- today() - days(1)  # yesterday\nyrs &lt;- 1981:(1981+20) # 20 yr climatology\ndates &lt;- sprintf(\"%d-%02d-%02d\", yrs, month(date), day(date))\npds &lt;- prism::prism_archive_subset(var, \"daily\", dates = dates)\n\n# web mercator for use with slippy maps\nproj4_3857 &lt;- \"+proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs +type=crs\"\n\nr_c &lt;- pd_stack(pds) |&gt; \n  raster::projectRaster(crs = proj4_3857) |&gt; \n  rast() |&gt; \n  mean(na.rm=T)\nnames(r_c) &lt;- glue::glue(\"{var}_historical\")\n# plot(r_c)\n\n# get_prism_dailys(type = var, dates = date, keepZip = F)\n# prism_archive_clean(var, \"daily\", dates = date)\n# prism_archive_crop(var, \"daily\", dates = date)\n\npd &lt;- prism::prism_archive_subset(var, \"daily\", dates = date)\nr_d &lt;- pd_stack(pd) |&gt; \n  raster::projectRaster(crs = proj4_3857) |&gt; \n  rast()\nnames(r_d) &lt;- var\n# plot(r_d)\n# plet(r_d, tiles=providers$Esri.OceanBasemap)\n\nvals &lt;- c(values(r_c, na.rm=T), values(r_d, na.rm=T))\npal &lt;- colorNumeric(\n  \"Spectral\", vals, reverse = T, na.color = \"transparent\")\n\n# leaflet() |&gt; \n#   addProviderTiles(\n#     providers$Stadia.StamenTonerLite) |&gt; \n#   addRasterImage(\n#     # r_c, colors = pal, opacity = 0.8, project = F) |&gt; \n#     r_d, colors = pal, opacity = 0.8, project = F) |&gt; \n#   addLegend(\n#     pal = pal, values = vals, title = var)\n\nleaflet() |&gt; \n  addMapPane(\"left\",  zIndex = 0) |&gt;\n  addMapPane(\"right\", zIndex = 0) |&gt;\n  addProviderTiles(\n    providers$CartoDB.DarkMatter,\n    options = pathOptions(pane = \"left\"),\n    group   = \"base\", \n    layerId = \"base_l\") |&gt; \n  addProviderTiles(\n    providers$CartoDB.DarkMatter,\n    options = pathOptions(pane = \"right\"),\n    group   = \"base\", \n    layerId = \"base_r\") |&gt; \n  addRasterImage(\n    r_c, colors = pal, opacity = 0.8, project = F,\n    options = leafletOptions(pane = \"left\"),\n    group = \"r_c\") |&gt; \n  addRasterImage(\n    r_d, colors = pal, opacity = 0.8, project = F,\n    options = leafletOptions(pane = \"right\"),\n    group = \"r_d\") |&gt; \n  addLayersControl(overlayGroups = c(\"r_c\", \"r_d\")) |&gt;  \n  addSidebyside(\n    layerId = \"sidecontrols\",\n    leftId  = \"base_l\",\n    rightId = \"base_r\") |&gt;\n  addControl(\n    HTML(glue(\n      \"&lt;b&gt;Historical&lt;/b&gt;&lt;br&gt;\n      ({paste(range(yrs), collapse = '-')})-{str_pad(month(date),2,pad='0')}-{str_pad(day(date),2,pad='0')}\")), \n    position = \"topleft\") |&gt; \n  addControl(\n    HTML(glue(\n      \"&lt;b&gt;Yesterday&lt;/b&gt;&lt;br&gt;\n      {date}\")), \n    position = \"topright\") |&gt; \n  # leaflet() |&gt; \n  # addTiles() |&gt; \n  addPolygons(\n    data = tbeptools::tbsegshed, \n    color=\"white\", weight = 2, fillOpacity=0) |&gt; \n  # mapview::mapView()\n  addLegend(\n    pal = pal, values = vals, title = var)\n\nd_c &lt;- terra::extract(\n  r_c,\n  tbeptools::tbsegshed,\n  exact = T, touches = T, method = \"bilinear\",\n  bind = T,\n  mean, na.rm=T) |&gt; \n  st_as_sf() |&gt; \n  st_drop_geometry()\n\nd_d &lt;- terra::extract(\n  r_d,\n  tbeptools::tbsegshed,\n  exact = T, touches = T, method = \"bilinear\",\n  bind = T,\n  mean, na.rm=T) |&gt; \n  st_as_sf() |&gt; \n  st_drop_geometry()\n\nd &lt;- d_c |&gt; \n  left_join(\n    d_d,\n    by = c(\"long_name\", \"bay_segment\"))\nd\n\n\noptions(repos=c(CRAN=“https://cran.rstudio.com/”)); renv::snapshot()\n\n2.6.1 Dewpoint to Humidity\n\nWhat is the Dewpoint & How is it Related to Relative Humidity & Heat Index? | OpenSnow\nOnce the dewpoint reaches above 55 degrees Fahrenheit (°F), the air becomes sticky and can be described as ‘muggy’ above 65°F. If the dewpoint reaches above 75°F, the air can often be described as ‘oppressive’…\nThe relative humidity is expressed in a percent (0-100%) and is the ratio of the amount of atmospheric moisture present relative to the amount that would be present if the air were saturated. What this means is that the relative humidity is dependent on both the dewpoint and the air temperature.\nHeat Index Calculation\n\nHeat Index Equation\nIt’s Not the Heat …\nSuppose you know the current temperature and the dew point. Can you get the relative humidity from them? Absolutely!\nHeat Index | NWS\nLawrence (2005) The Relationship between Relative Humidity and the Dewpoint Temperature in Moist Air: A Simple Conversion and Applications Bulletin of the American Meteorological Society\nWhat is Apparent Temperature?\n\n\nTODO: - [ ] summarize by tbeptools::tbsegshed, zip code - [ ] compare these precip data w/ Water District data to make case for using PRISM data\nQuestions:\n\nGiven variability within each polygon, which of these products shall we use to plot: min(min_temp), mean(mean_temp), max(max_temp); min(mean_temp), mean(mean_temp), max(max_temp)?\n\n\n\n2.6.2 Communicating results\n\nChoi et al. (2024) North-South disparity in impact of climate change on “outdoor days”. Journal of Climate\n\nnews summary: A new way to quantify climate change impacts: “Outdoor days” | MIT News | Massachusetts Institute of Technology\nShiny app: California Outdoor Days | Eltahir Research Group",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#sea",
    "href": "data.html#sea",
    "title": "2  Data",
    "section": "2.7 Sea",
    "text": "2.7 Sea\n\n2.7.1 Sea Level\nSea level rise occurs from principally two sources: 1) thermal expansion; and 2) freshwater inputs from glacial melting. Data for these trends can be obtained from NOAA’s Sea Level Trends (Figure 2.1)\nTypes of data:\n\nObserved (past, present) - tide gauge - satellite, e.g. Laboratory for Satellite Altimetry / Sea Level Rise\n\nLevel-3 products distributed through NOAA CoastWatch (Sea Level Anomaly and along-track altimetry)\n\nProjected (future). modeled\n\n\n2.7.1.1 Gauges\n\n\n\n\n\n\nFigure 2.1: Screenshot of NOAA’s Sea Level Trends zoomed into the Tampa Bay.\n\n\n\nhttps://tidesandcurrents.noaa.gov/sltrends/\n\nPORTS: Tampa Bay PORTS - NOAA Tides & Currents\napi.tidesandcurrents.noaa.gov\nCO-OPS Data Retrieval API\nCO-OPS Metadata API v1.0\n\nhttps://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations/id.extension https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations/8726724.json https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations/8726724/details.json - “established”: “1973-04-19 00:00:00.0” - “origyear”: “1995-07-27 23:00:00.0” https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations/8726724/products.json - “name”: “Water Levels”, - “value”: “https://tidesandcurrents.noaa.gov/waterlevels.html?id=8726724”\nhttps://tidesandcurrents.noaa.gov/sltrends/sltrends_station.shtml?id=8726724 https://tidesandcurrents.noaa.gov/sltrends/data/8726724_meantrend.csv\nInundation History - NOAA Tides & Currents\n\nFAQ for Sea Level Trends | NOAA Tides & Currents &gt; Relative Sea Level Trends reflect changes in local sea level over time and are typically the most critical sea level trend for many coastal applications, including coastal mapping, marine boundary delineation, coastal zone management, coastal engineering, sustainable habitat restoration design, and the general public enjoying their favorite beach. This website focuses on relative sea level trends, computed from monthly averages of hourly water levels observed at specific tide stations, called monthly mean sea level.\n\nSee tbeptools additions:\n\nsealevelstations.R\nread_importsealevels.R\nsealevels.Rmd\nSea Level Trends - NOAA Tides & Currents\n\n\nClearwater Beach, FL\n8726724\nThe relative sea level trend is 4.33 mm/year with a 95% confidence interval of +/- 0.52 mm/year based on monthly mean sea level data from 1973 to 2023 which is equivalent to a change of 1.42 feet in 100 years.\n\n\nRelative Sea Level Trend\nAnnual Mean Relative Sea Level\nInterannual Variation\nAverage Seasonal Cycle\nTimelapse – Google Earth Engine\n\n\nEast Bay, FL\n8726674\nThe relative sea level trend is 5.8 mm/year with a 95% confidence interval of +/- 0.85 mm/year based on monthly mean sea level data from 1976 to 2023 which is equivalent to a change of 1.90 feet in 100 years.\nPort Manatee, FL\n8726384\nThe relative sea level trend is 5.5 mm/year with a 95% confidence interval of +/- 0.68 mm/year based on monthly mean sea level data from 1976 to 2023 which is equivalent to a change of 1.80 feet in 100 years.\nSt. Petersburg, FL\n8726520\nThe relative sea level trend is 3.09 mm/year with a 95% confidence interval of +/- 0.23 mm/year based on monthly mean sea level data from 1947 to 2023 which is equivalent to a change of 1.01 feet in 100 years.\n\n\nInundation Dashboard - NOAA Tides & Currents\n\n\n\n\n2.7.2 Surface Temperature\n\ncoral reefs: ecosystem health, ecotourism\nfisheries\nenergy for hurricanes\nbackground: NOAA Coral Reef Watch Tutorial\n\nERDDAP - Sea Surface Temperature, NOAA Coral Reef Watch Daily Global 5km Satellite SST (CoralTemp), 1985-present, Daily - Data Access Form\n\n\nOutput is stored in a single raster file containing about a little over 13K layers, which seems to read and render reasonably fast (whereas for the more numerous PRISM layers, it was way too slow).\n\nBasic Detection and Visualisation of Events • heatwaveR\n\n\n\n\n\nCode\nlibrarian::shelf(\n  sf, tbeptools, mapview)\n\ntbshed_buf &lt;- tbshed |&gt; \n  st_buffer(10000) |&gt; # buffer by 10 km\n  st_bbox() |&gt; \n  st_as_sfc() |&gt; \n  st_as_sf()\n  \n# st_bbox(tbshed_buf) |&gt; round(1)\n#  xmin  ymin  xmax  ymax \n# -83.0  27.3 -81.8  28.5\n# after clipping to non-NA raster values\nbbox = c(xmin = -83.0, ymin = 27.2, xmax = -82.3, ymax= 28.5)\nsst_bbox &lt;- bbox |&gt;\n  sf::st_bbox() |&gt;\n  sf::st_as_sfc() |&gt;\n  sf::st_as_sf(crs = \"+proj=longlat +datum=WGS84 +no_defs\")\n\nmapView(tbsegshed, col.regions=\"gray\") + \n  mapView(tbshed_buf, col.regions = \"blue\") + \n  mapView(sst_bbox, col.regions = \"red\")\n\n\n\n\nCode\nlibrarian::shelf(\n  marinebon/extractr,\n  here)\n\ned_extract(\n  ed        = ed_info(\"https://coastwatch.noaa.gov/erddap/griddap/noaacrwsstDaily.html\"),\n  var       = \"analysed_sst\",\n  bbox      = c(xmin = -83.0, ymin = 27.2, xmax = -82.3, ymax= 28.5),\n  aoi       = tbeptools::tbsegshed,\n  zonal_csv = here(\"data/sst/tbep_sst.csv\"),\n  rast_tif  = here(\"data/sst/tbep_sst.tif\"),\n  mask_tif = F)\n\n\n\n\nCode\nlibrarian::shelf(\n  ggplot2, here, highcharter, lubridate, plotly, readr)\n\n# data(\"mpg\", \"diamonds\", \"economics_long\", package = \"ggplot2\")\n# economics_long2 &lt;- dplyr::filter(economics_long, variable %in% c(\"pop\", \"uempmed\", \"unemploy\"))\n# hchart(economics_long2, \"line\", hcaes(x = date, y = value01, group = variable))\n\nsst_csv &lt;- here(\"data/sst/tb_sst.csv\")\nd_sst   &lt;- read_csv(sst_csv, show_col_types = F)\ntable(d_sst$bay_segment)\n#   BCB    HB   LTB    MR   MTB   OTB   TCB \n# 13169 13169 13169 13169 13169 13169 13169 \n\nbay_segment &lt;- \"BCB\"\n\nd &lt;- d_sst |&gt; \n  filter(bay_segment == !!bay_segment) |&gt; \n  mutate(\n    year  = year(time),\n    # yday  = yday(time),\n    date  = sprintf(\n      \"%d-%02d-%02d\", \n      year(today()), month(time), day(time) ) |&gt; \n      as.POSIXct(),\n    color = case_when(\n      year == year(today())     ~ \"red\",\n      year == year(today()) - 1 ~ \"orange\",\n      .default = \"gray\") ) |&gt; \n  # select(year, yday, date, color, val) |&gt; \n  # arrange(year, yday, date, val)\n  select(time, year, date, color, val) |&gt; \n  arrange(year, date, val)\n# table(d$yday) |&gt; range()\n\nyrs    &lt;- as.character(unique(d$year))\ncolors &lt;- setNames(rep(\"darkgray\", length(yrs)), yrs)\ncolors[as.character(year(today()))]     &lt;- \"red\"\ncolors[as.character(year(today()) - 1)] &lt;- \"orange\"\n\nlibrarian::shelf(\n  slider, scales)\n\nd &lt;- d |&gt;\n  group_by(year) |&gt; \n  mutate(\n    val_sl = slider::slide_mean(\n      val, before = 3L, after = 3L, step = 1L, \n      complete = F, na_rm = T),\n    txt_date = as.Date(time),\n    txt_val  = round(val_sl, 2) ) |&gt; \n  select(-time) |&gt; \n  ungroup()\n\n# TODO: darkly theme w/ bslib\ng &lt;- ggplot(\n  d,\n  aes(\n    x     = date, \n    y     = val_sl,\n    group = year,\n    color = factor(year),\n    date  = txt_date,\n    value = txt_val)) +  # frame = yday\n  geom_line(\n    # aes(text  = text),\n    alpha = 0.6) + \n  scale_colour_manual(\n    values = colors) + \n  theme(legend.position = \"none\") +\n  scale_x_datetime(\n    labels = date_format(\"%b %d\")) + \n  labs(\n    x = \"Day of year\",\n    y = \"Temperature ºC\")\ng\n# x, y, alpha, color, group, linetype, size\n\n# add color theming\n\n# https://rstudio.github.io/thematic/articles/auto.html\n\nggplotly(g, tooltip=c(\"date\",\"value\"))\n\n# https://plotly-r.com/scatter-traces 3\n# https://plotly-r.com/client-side-linking 16\n\n\n# https://stackoverflow.com/questions/76435688/how-to-autoplay-a-plotly-chart-in-shiny\nd |&gt; \n  plot_ly(\n    x     = ~date,\n    y     = ~val,\n    frame = ~yday,\n    # group = ~year,\n    # color = ~color,\n    type  = 'scatter', \n    mode  = 'lines',\n    # marker = list(size = 20),\n    showlegend = F,\n    transforms = list(\n    list(\n      type = 'groupby',\n      groups = d$year,\n      styles = list(\n        list(target = 2024, value = list(line =list(color = 'red'))),\n        list(target = 2023, value = list(line =list(color = 'orange'))),\n        list(target = 2022, value = list(line =list(color = 'darkgray'))) ) ) ) )\n    \n  \n  animation_button(visible = T) |&gt; \n  onRender(\"\n    function(el,x) {\n      Plotly.animate(el);\n    }\")\n\nlibrary(plotly)\nlibrary(htmlwidgets)\n\ndf &lt;- data.frame(\n  x = c(1,2,1), \n  y = c(1,2,1), \n  f = c(1,2,3)\n)\ndf %&gt;%\n  plot_ly(\n    x = ~x,\n    y = ~y,\n    frame = ~f,\n    type = 'scatter',\n    mode = 'markers',\n    marker = list(size = 20),\n    showlegend = FALSE\n  ) %&gt;% \n  animation_button(visible = TRUE) %&gt;%\n  onRender(\"\n        function(el,x) {\n          Plotly.animate(el);\n        }\")\n\n\n# https://stackoverflow.com/questions/61152879/change-the-frame-label-in-plotly-animation\nDF &lt;- data.frame(\n  year = rep(seq(1980L, 2020L), each = 12), \n  month = rep(1:12, 41), \n  month_char = rep(factor(month.abb), 41),\n  avg_depth = runif(492) )\n# with(DF, paste0(sprintf(\"%02d\", month), \" - \", month_char) )\nfig &lt;- DF |&gt; \n  plot_ly(\n    x = ~year, \n    y = ~avg_depth,\n    frame = ~paste0(sprintf(\"%02d\", month), \" - \", month_char),\n    type = 'bar') |&gt; \n  animation_slider(\n    currentvalue = list(prefix = \"Month: \") )\n\nfig\n\n# https://stackoverflow.com/questions/50843134/r-plotly-animated-chart-only-showing-groups-with-data-in-initial-frame\n\ndates &lt;- 2000:2010\ncountries &lt;- c(\"US\", \"GB\", \"JP\")\ndf &lt;- merge(dates, countries, all=TRUE)\nnames(df) &lt;- c(\"Date\", \"Country\")\n\n\ndf$x &lt;- rnorm(nrow(df))\ndf$y &lt;- rnorm(nrow(df))\n\ndf[1:3, c(\"x\", \"y\")] &lt;- NA\n\n\np &lt;- ggplot(df, aes(x, y, color = Country)) +\n  geom_point(aes(frame = Date)) + theme_bw()\n\nggplotly(p)\n\n# other\n\ng &lt;- ggplot(\n  d,\n  aes(\n    x     = date, \n    y     = val, \n    color = factor(year))) +\n  geom_line(alpha = 0.6) + \n  scale_colour_manual(\n    values = colors) + \n  theme(legend.position = \"none\")\ng\n\n            \np &lt;- ggplotly(g) |&gt; \n  onRender(\"\n    function(el,x) {\n      Plotly.animate(el);\n    }\")\np\n\nd |&gt; \n  hchart(\n    \"line\", # \"line\"\n    hcaes(\n      x            = date, \n      y            = val, \n      group        = year,\n      segmentColor = clr),\n    showInLegend = F)\n\nmpgman2 &lt;- count(mpg, manufacturer, year)\nhchart(\n  mpgman2, \n  \"bar\",\n  hcaes(x = manufacturer, y = n, group = year),\n  color = c(\"#7CB5EC\", \"#F7A35C\"),\n  name = c(\"Year 1999\", \"Year 2008\"),\n  showInLegend = c(TRUE, FALSE) # only show the first one in the legend\n  )\n\n\n\n\n2.7.3 Acidification",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#extreme-weather",
    "href": "data.html#extreme-weather",
    "title": "2  Data",
    "section": "2.8 Extreme Weather",
    "text": "2.8 Extreme Weather\nOr “Severe Weather”\n\nSWDI vignette • rnoaa\n\n\n2.8.1 Hurricanes\n\nproperty damage\n\n\n\nCode\nrnoaa::coops_search()\n# swdi - Severe Weather Data Inventory (SWDI) vignette\n\n\n\n\n2.8.2 Floods",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#old",
    "href": "data.html#old",
    "title": "2  Data",
    "section": "2.9 OLD",
    "text": "2.9 OLD\n\n2.9.1 Satellite\n\nNOAA / NESDIS / STAR - Laboratory for Satellite Altimetry / Sea Level Rise\n\n\n\nCode\nslr_nc    &lt;- here(\"data/slr/slr_map_txj1j2.nc\")\nr_slr_gcs &lt;- rast(slr_nc)  # 0.5 degree resolution\nr_slr_mer &lt;- projectRasterForLeaflet(r_slr_gcs, method=\"bilinear\")\n\nb &lt;- st_bbox(tbsegshed)\nr_slr_tb_mer &lt;- rast(slr_nc) |&gt; \n  crop(b) # |&gt; \n  # projectRasterForLeaflet(method=\"bilinear\")\n# only one value for Tampa Bay extracted at 0.5 degree resolution\n# values(r_slr_tb_mer, mat=F, na.rm=T)  # 5.368306\n\nb &lt;- st_bbox(tbshed)\nplet(r_slr_mer, tiles=providers$Esri.OceanBasemap) |&gt; \n  addProviderTiles(providers$CartoDB.DarkMatterOnlyLabels) |&gt; \n  addPolygons(data = tbsegshed) |&gt;\n  fitBounds(\n    lng1 = b[[\"xmin\"]], lat1 = b[[\"ymin\"]], \n    lng2 = b[[\"xmax\"]], lat2 = b[[\"ymax\"]])\n\n\n\n\n\n\n\nFigure 2.1: Screenshot of NOAA’s Sea Level Trends zoomed into the Tampa Bay.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Beck, Marcus W., G. E. Raulerson, M. C. Burke, J. Whalen, S. Scolaro,\nand E. T. Sherwood. 2021. “Tampa Bay Estuary Program: Data\nManagement Standard Operating Procedures.” St. Petersburg,\nFlorida.\n\n\nBeck, Marcus W., Meagan N. Schrandt, Michael R. Wessel, Edward T.\nSherwood, Gary E. Raulerson, Adhokshaja Achar Budihal Prasad, and\nBenjamin D. Best. 2021. “Tbeptools: An R Package for Synthesizing\nEstuarine Data for Environmental Research.” Journal of Open\nSource Software 6 (65): 3485. https://doi.org/10.21105/joss.03485.\n\n\nBurke, M., and M. Amaral. 2020. “2021-2025 Strategic Plan.”\nSt. Petersburg, Florida.",
    "crumbs": [
      "References"
    ]
  }
]